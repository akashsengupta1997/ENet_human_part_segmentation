# coding=utf-8
from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D
from keras.layers.core import Activation
from keras.layers.merge import add
from keras.layers.normalization import BatchNormalization


def bottleneck_enet_dec(encoder, output, upsample=False, reverse_module=False):
    internal = output // 4

    x = Conv2D(internal, (1, 1), use_bias=False)(encoder)
    x = BatchNormalization(momentum=0.1)(x)
    x = Activation('relu')(x)
    if not upsample:
        x = Conv2D(internal, (3, 3), padding='same', use_bias=True)(x)
    else:
        x = Conv2DTranspose(filters=internal, kernel_size=(3, 3), strides=(2, 2),
                            padding='same')(x)
    x = BatchNormalization(momentum=0.1)(x)
    x = Activation('relu')(x)

    x = Conv2D(output, (1, 1), padding='same', use_bias=False)(x)

    other = encoder
    if encoder.get_shape()[-1] != output or upsample:
        other = Conv2D(output, (1, 1), padding='same', use_bias=False)(other)
        other = BatchNormalization(momentum=0.1)(other)
        if upsample and reverse_module is not False:
            other = UpSampling2D(size=(2, 2))(other)

    if upsample and reverse_module is False:
        decoder = x
    else:
        x = BatchNormalization(momentum=0.1)(x)
        decoder = add([x, other])
        decoder = Activation('relu')(decoder)

    return decoder


def build_enet_dec(encoder, nc):
    enet = bottleneck_enet_dec(encoder, 64, upsample=True,
                               reverse_module=True)  # bottleneck 4.0
    enet = bottleneck_enet_dec(enet, 64)  # bottleneck 4.1
    enet = bottleneck_enet_dec(enet, 64)  # bottleneck 4.2
    enet = bottleneck_enet_dec(enet, 16, upsample=True, reverse_module=True)  # bottleneck 5.0
    enet = bottleneck_enet_dec(enet, 16)  # bottleneck 5.1

    enet = Conv2DTranspose(filters=nc, kernel_size=(2, 2), strides=(2, 2), padding='same')(
        enet)
    return enet


def build_enet_dec_64(encoder, nc):
    enet = bottleneck_enet_dec(encoder, 64, upsample=False,
                               reverse_module=True)  # bottleneck 4.0
    enet = bottleneck_enet_dec(enet, 64)  # bottleneck 4.1
    enet = bottleneck_enet_dec(enet, 64)  # bottleneck 4.2
    enet = bottleneck_enet_dec(enet, 16, upsample=False, reverse_module=True)  # bottleneck 5.0
    enet = bottleneck_enet_dec(enet, 16)  # bottleneck 5.1

    enet = Conv2DTranspose(filters=nc, kernel_size=(2, 2), strides=(1, 1), padding='same')(
        enet)
    return enet
